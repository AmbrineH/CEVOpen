<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The initial feature vector was reduced using feature selection by input sensitivity as goal function. When one or more of the inputs have a relatively small sensitivity in comparison to the others, the input layer of the ANN can be reduced by dropping them, and a smaller-size network can be successfully retrained in most cases [
 <xref rid="B45-sensors-18-01922" ref-type="bibr" class="xref">45</xref>]. Sensitivity analysis provides extra knowledge on the response of the model to changes in each input. This method was initially developed by Lek et al. [
 <xref rid="B46-sensors-18-01922" ref-type="bibr" class="xref">46</xref>] and later analyzed in more detail by Gevrey [
 <xref rid="B47-sensors-18-01922" ref-type="bibr" class="xref">47</xref>]. The response of the best network is inspected by varying each predictor variable in small steps while locking all other input parameters at their mean value [
 <xref rid="B48-sensors-18-01922" ref-type="bibr" class="xref">48</xref>] (see vii. in 
 <xref ref-type="fig" rid="sensors-18-01922-f002" class="xref">Figure 2</xref>). Those inputs with a higher sensitivity were retained and those with a lower sensitivity were removed. To determine the optimal size of the input layer for the ANN, an internal cross-validation approach was followed using global classification accuracy as goal function. The search procedure followed a sequential approach by adding peaks according to their best ranking among the four outputs. In the first step, the peaks ranking first for any of the outputs are added, in the second step the peaks ranking second for any output are added. The aforementioned procedure was continued to have all 22 peaks as inputs. The combination of peaks that provides the best classification accuracy is selected.
</p>
